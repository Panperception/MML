{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Panperception/MML/blob/main/MML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize"
      ],
      "metadata": {
        "id": "wQhR8ughJXa2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOrA-Uq_tJqB"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTyO8Jc964st"
      },
      "source": [
        "## Learning on Many Manifolds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo Code 0"
      ],
      "metadata": {
        "id": "Cc5vcJTYNa2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class SharedAutoencoder(nn.Module):\n",
        "    def __init__(self, latent_dim, num_classes):\n",
        "        super(SharedAutoencoder, self).__init__()\n",
        "\n",
        "        # Shared encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*7*7, latent_dim)\n",
        "        )\n",
        "\n",
        "        # Separate latent space for each class (one per class)\n",
        "        self.latent_spaces = nn.ModuleList([nn.Linear(latent_dim, latent_dim) for _ in range(num_classes)])\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 64*7*7),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (64, 7, 7)),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, class_idx):\n",
        "        # Shared encoder\n",
        "        z = self.encoder(x)\n",
        "\n",
        "        # Latent space transformation per class\n",
        "        z_class = self.latent_spaces[class_idx](z)\n",
        "\n",
        "        # Decoder\n",
        "        reconstructed = self.decoder(z_class)\n",
        "        return reconstructed, z_class\n",
        "\n",
        "def train(model, dataloader, epochs=5, learning_rate=0.001):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for data, targets in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            # Use the class index from the targets (it's already an integer)\n",
        "            for i in range(data.size(0)):  # For each batch sample\n",
        "                class_idx = targets[i].item()  # Convert target to int\n",
        "                reconstructed, _ = model(data[i:i+1], class_idx)  # Use single image per forward pass\n",
        "                loss = criterion(reconstructed, data[i:i+1])  # Reconstruction loss for the image\n",
        "                loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(dataloader)}')\n",
        "\n",
        "# Data Preparation (Using MNIST for simplicity)\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Model Initialization\n",
        "latent_dim = 128\n",
        "num_classes = 10  # 10 classes for MNIST\n",
        "model = SharedAutoencoder(latent_dim, num_classes)\n",
        "\n",
        "# Training the Model\n",
        "train(model, train_loader, epochs=5)\n",
        "\n",
        "# Visualization of Reconstruction\n",
        "def visualize_reconstruction(model, dataloader, class_idx=0):\n",
        "    model.eval()\n",
        "    data, targets = next(iter(dataloader))\n",
        "    reconstructed, _ = model(data, class_idx)\n",
        "\n",
        "    # Plot original and reconstructed images\n",
        "    fig, axes = plt.subplots(2, 10, figsize=(15, 5))\n",
        "    for i in range(10):\n",
        "        axes[0, i].imshow(data[i].squeeze().cpu().numpy(), cmap='gray')\n",
        "        axes[1, i].imshow(reconstructed[i].squeeze().cpu().detach().numpy(), cmap='gray')\n",
        "        axes[0, i].axis('off')\n",
        "        axes[1, i].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Visualize reconstruction for a specific class\n",
        "visualize_reconstruction(model, train_loader, class_idx=0)  # For class 0 (e.g., '0' digit in MNIST)\n"
      ],
      "metadata": {
        "id": "uhGpA7i1Nkvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo Code 1"
      ],
      "metadata": {
        "id": "f21ZDUzNJglG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -----------------------\n",
        "# Model Components\n",
        "# -----------------------\n",
        "\n",
        "class SharedEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.shared = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28 * 28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.shared(x)\n",
        "\n",
        "class LatentBranch(nn.Module):\n",
        "    def __init__(self, latent_dim=16):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(128, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "class SharedDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim=16):\n",
        "        super().__init__()\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 28 * 28),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.decoder(z).view(-1, 1, 28, 28)\n",
        "\n",
        "class MultiLatentAutoencoder(nn.Module):\n",
        "    def __init__(self, latent_dim=16, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.encoder = SharedEncoder()\n",
        "        self.latent_branches = nn.ModuleList([LatentBranch(latent_dim) for _ in range(num_classes)])\n",
        "        self.decoder = SharedDecoder(latent_dim)\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        shared = self.encoder(x)\n",
        "        latents = torch.stack([branch(shared) for branch in self.latent_branches], dim=1)  # [B, C, latent_dim]\n",
        "        z = latents[torch.arange(x.size(0)), labels]  # Select class-specific latent\n",
        "        out = self.decoder(z)\n",
        "        return out\n",
        "\n",
        "# -----------------------\n",
        "# Dataset\n",
        "# -----------------------\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "# -----------------------\n",
        "# Training Setup\n",
        "# -----------------------\n",
        "\n",
        "model = MultiLatentAutoencoder().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# -----------------------\n",
        "# Training Loop\n",
        "# -----------------------\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images, labels)\n",
        "        loss = criterion(outputs, images)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# -----------------------\n",
        "# Evaluation / Visualization\n",
        "# -----------------------\n",
        "\n",
        "model.eval()\n",
        "images, labels = next(iter(test_loader))\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    recon = model(images, labels)\n",
        "\n",
        "# Show original and reconstructed\n",
        "def show_images(original, reconstructed, n=10):\n",
        "    plt.figure(figsize=(15, 3))\n",
        "    for i in range(n):\n",
        "        # Original\n",
        "        plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(original[i].cpu().squeeze(), cmap='gray')\n",
        "        plt.axis('off')\n",
        "        # Reconstructed\n",
        "        plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(reconstructed[i].cpu().squeeze(), cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(\"Top: Original | Bottom: Reconstructed\", fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "show_images(images, recon)\n"
      ],
      "metadata": {
        "id": "0MxApxnIJ7VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo Code 2\n",
        "### Key Takeaways\n",
        "* Each class's decoder models a distinct digit manifold.\n",
        "* RandomAffine introduces group action (SO(2), translation), challenging the model to be invariant or equivariant.\n",
        "* Decoder selection requires label knowledge; removing this label makes inference NP-hard (you’d need to guess decoder + latent code jointly).\n",
        "* This aligns with the theoretical proof sketch — combinatorial search across submanifolds under transformations."
      ],
      "metadata": {
        "id": "lmltZ0H7JlEn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vqSCCUlH7YJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Data Loading with Group Action (rotation) ---\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomAffine(degrees=30),  # simulates group action SO(2)\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "transform_test = transforms.ToTensor()\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# --- 2. Shared Encoder (learns common latent structure) ---\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim=32):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, stride=2, padding=1),  # 28 -> 14\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, 3, stride=2, padding=1),  # 14 -> 7\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.fc = nn.Linear(32 * 7 * 7, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n",
        "\n",
        "# --- 3. Class-Specific Decoder (models separate submanifolds) ---\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim=32):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(latent_dim, 32 * 7 * 7)\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),  # 7 -> 14\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),   # 14 -> 28\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = self.fc(z)\n",
        "        z = z.view(-1, 32, 7, 7)\n",
        "        return self.deconv(z)\n",
        "\n",
        "# --- 4. Full Model with Shared Encoder + Per-Class Decoders ---\n",
        "class ManifoldAutoencoder(nn.Module):\n",
        "    def __init__(self, latent_dim=32, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(latent_dim)\n",
        "        self.decoders = nn.ModuleList([Decoder(latent_dim) for _ in range(num_classes)])\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        z = self.encoder(x)\n",
        "        recon = torch.zeros_like(x)\n",
        "        for i in range(x.size(0)):\n",
        "            recon[i] = self.decoders[labels[i]](z[i].unsqueeze(0))\n",
        "        return recon\n",
        "\n",
        "# --- 5. Training the Model ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ManifoldAutoencoder(latent_dim=32).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "def train(model, loader, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            x_hat = model(x, y)\n",
        "            loss = loss_fn(x_hat, x)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1} | Avg Loss: {total_loss / len(loader):.4f}\")\n",
        "\n",
        "train(model, train_loader, epochs=5)\n",
        "\n",
        "# --- 6. Visualize Reconstructions ---\n",
        "def visualize_reconstruction(model, loader):\n",
        "    model.eval()\n",
        "    x, y = next(iter(loader))\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    with torch.no_grad():\n",
        "        x_hat = model(x, y)\n",
        "    x, x_hat = x.cpu(), x_hat.cpu()\n",
        "\n",
        "    fig, axes = plt.subplots(2, 10, figsize=(12, 3))\n",
        "    for i in range(10):\n",
        "        axes[0, i].imshow(x[i][0], cmap='gray')\n",
        "        axes[1, i].imshow(x_hat[i][0], cmap='gray')\n",
        "        axes[0, i].axis('off')\n",
        "        axes[1, i].axis('off')\n",
        "    plt.suptitle(\"Top: Original | Bottom: Reconstructed via Class-Specific Decoder\")\n",
        "    plt.show()\n",
        "\n",
        "visualize_reconstruction(model, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MwfvxNcsvAP"
      },
      "source": [
        "## Demo Code 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fwl7sOGmsytb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# MNIST data loader\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Shared Encoder\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim=32):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28*28, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, latent_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Class-specific Decoder\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim=32):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 28*28),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        x_hat = self.net(z)\n",
        "        return x_hat.view(-1, 1, 28, 28)\n",
        "\n",
        "# Full Autoencoder\n",
        "class MultiDecoderAutoencoder(nn.Module):\n",
        "    def __init__(self, num_classes=10, latent_dim=32):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(latent_dim)\n",
        "        self.decoders = nn.ModuleList([Decoder(latent_dim) for _ in range(num_classes)])\n",
        "\n",
        "    def forward(self, x, label):\n",
        "        z = self.encoder(x)\n",
        "        x_hat = torch.zeros_like(x)\n",
        "        for i in range(len(self.decoders)):\n",
        "            mask = (label == i)\n",
        "            if mask.any():\n",
        "                x_hat[mask] = self.decoders[i](z[mask])\n",
        "        return x_hat\n",
        "\n",
        "model = MultiDecoderAutoencoder().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Training\n",
        "def train_epoch(model, loader, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        x_hat = model(x, y)\n",
        "        loss = criterion(x_hat, x)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "    print(f\"[Train Loss] {total_loss / len(loader.dataset):.4f}\")\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(1, 6):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    train_epoch(model, train_loader, optimizer)\n",
        "\n",
        "# Unsupervised decoder inference\n",
        "def infer_decoder_unsupervised(model, x_batch):\n",
        "    model.eval()\n",
        "    x_batch = x_batch.to(device)\n",
        "    with torch.no_grad():\n",
        "        z = model.encoder(x_batch)\n",
        "        errors = []\n",
        "        for decoder in model.decoders:\n",
        "            x_hat = decoder(z)\n",
        "            err = F.mse_loss(x_hat, x_batch, reduction='none')\n",
        "            err = err.view(err.size(0), -1).mean(dim=1)\n",
        "            errors.append(err.unsqueeze(1))\n",
        "        all_errors = torch.cat(errors, dim=1)\n",
        "        best_decoder = all_errors.argmin(dim=1)\n",
        "    return best_decoder.cpu()\n",
        "\n",
        "# Evaluate unsupervised accuracy\n",
        "def evaluate_unsupervised(model, loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for x, y in loader:\n",
        "        pred = infer_decoder_unsupervised(model, x)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += x.size(0)\n",
        "    print(f\"[Unsupervised Inference Accuracy] {correct}/{total} = {correct/total:.2%}\")\n",
        "\n",
        "evaluate_unsupervised(model, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91iBeVEJaT7W"
      },
      "source": [
        "## XAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n",
        "import shap"
      ],
      "metadata": {
        "id": "jP0BGs4BcRUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xai_model = model_dmlp_adam"
      ],
      "metadata": {
        "id": "zlKwZ8MBdTtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJvCToHZaT7W"
      },
      "outputs": [],
      "source": [
        "img_rows=32\n",
        "img_cols=32\n",
        "background = x_train[np.random.choice(x_train.shape[0], 500, replace=False)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-WgKEAmaT7W"
      },
      "outputs": [],
      "source": [
        "e = shap.DeepExplainer(xai_model, background)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVXFGLGmaT7W"
      },
      "outputs": [],
      "source": [
        "background = x_train[np.random.choice(x_train.shape[0], 500, replace=False)]\n",
        "e = shap.DeepExplainer(xai_model, background)\n",
        "shap_values = e.shap_values(x_test[1:5])\n",
        "shap.image_plot(shap_values, -x_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkYmfsk4aT7W"
      },
      "outputs": [],
      "source": [
        "s_values = [(np.reshape(x,(x.shape[0],img_rows,img_cols))) for x in shap_values]\n",
        "x_tst = np.reshape(x_test[1:5],(x_test[1:5].shape[0],img_rows,img_cols))\n",
        "shap.image_plot(s_values, -x_tst)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYmluWINaT7X"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.keras.losses import categorical_crossentropy\n",
        "from cxplain import MLPModelBuilder, ZeroMasking, CXPlain\n",
        "\n",
        "x_train, y_train, x_test = ....  # Your dataset\n",
        "explained_model = ...    # The model you wish to explain.\n",
        "\n",
        "# Define the model you want to use to explain your __explained_model__.\n",
        "# Here, we use a neural explanation model with a\n",
        "# multilayer perceptron (MLP) architecture.\n",
        "model_builder = MLPModelBuilder(num_layers=2, num_units=64, batch_size=256, learning_rate=0.001)\n",
        "\n",
        "# Define your masking operation - the method of simulating the\n",
        "# removal of input features used internally by CXPlain - ZeroMasking is typically a sensible default choice for tabular and image data.\n",
        "masking_operation = ZeroMasking()\n",
        "\n",
        "# Define the loss with which each input features' associated reduction in prediction error is calculated.\n",
        "loss = categorical_crossentropy\n",
        "\n",
        "# Build and fit a CXPlain instance.\n",
        "explainer = CXPlain(explained_model, model_builder, masking_operation, loss)\n",
        "explainer.fit(x_train, y_train)\n",
        "\n",
        "# Use the __explainer__ to obtain explanations for the predictions of your __explained_model__.\n",
        "attributions = explainer.explain(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZz2B8zYtJ9V"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Overall F1 score\n",
        "y_pred=np.argmax(model_dmlp_adam.predict(x_test), axis=1)\n",
        "print(\"F1 Score:  \", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Precision: \", precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Recall:    \", recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Accuracy:    \", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Overall F1 score\n",
        "\n",
        "#intermediate_layer_model = keras.Model(inputs=model_dmlp_SGD.input,\n",
        "#                                 outputs=model_dmlp_SGD.layers[0].output)\n",
        "#intermediate_output = intermediate_layer_model.predict(x_test)\n",
        "#ws=model_dmlp_SGD.layers[0].get_weights()\n",
        "#y00=np.matmul(x_test,ws[0])+np.tile(ws[1],[x_test.shape[0],1])\n",
        "\n",
        "\n",
        "y_pred=np.argmax(model_dmlp_SGD.predict(x_test), axis=1)\n",
        "print(\"F1 Score:  \", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Precision: \", precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Recall:    \", recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Accuracy:    \", accuracy_score(y_test, y_pred))\n",
        "#print(\"Accuracy:    \", np.mean(y_pred.reshape(1171,1)==y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BsMzxbcpyhR"
      },
      "source": [
        "## Pretrained VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqeXmqMRlkC2"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#img_size_target = 32;\n",
        "#img_input = tf.keras.layers.Input(shape=(img_size_target, img_size_target,1))\n",
        "#img_conc = tf.keras.layers.Concatenate()([img_input, img_input, img_input])\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "## Loading VGG16 model\n",
        "pre_model = VGG16(include_top=False, weights='imagenet', input_shape=(32,32,3))\n",
        "pre_model.trainable = False ## Not trainable weights\n",
        "\n",
        "from keras import layers, models\n",
        "\n",
        "flatten_layer = layers.Flatten()\n",
        "dense_layer_1 = layers.Dense(128, activation='relu')\n",
        "dense_layer_2 = layers.Dense(32, activation='relu')\n",
        "prediction_layer = layers.Dense(2, activation='softmax')\n",
        "\n",
        "model = models.Sequential([\n",
        "    pre_model,\n",
        "    flatten_layer,\n",
        "    dense_layer_1,\n",
        "    dense_layer_2,\n",
        "    prediction_layer\n",
        "])\n",
        "\n",
        "pre_model.summary()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dS_Mfwr-VGDv"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKrnIqxuXu0d"
      },
      "outputs": [],
      "source": [
        "one_hot_labels = keras.utils.np_utils.to_categorical(y_train, num_classes=2)\n",
        "hist_v16=model.fit(np.repeat(x_train.reshape((x_train.shape[0],32,32,1)), 3, axis=3), one_hot_labels, epochs=100, validation_split=0.2, batch_size=32, callbacks=[])\n",
        "\n",
        "plt.plot(hist_v16.history[\"loss\"]);\n",
        "plt.xlabel('Epochs');\n",
        "plt.ylabel('Training Error');\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVsHpjPNoMiA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Overall F1 score\n",
        "y_pred=np.argmax(model.predict(np.repeat(x_test.reshape((x_test.shape[0],32,32,1)), 3, axis=3)), axis=1)\n",
        "print(\"F1 Score:  \", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Precision: \", precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Recall:    \", recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Accuracy:    \", accuracy_score(y_test, y_pred))\n",
        "print(\"Accuracy:    \", np.mean(y_pred.reshape(1171,1)==y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###XAI Demo of VGG16 Model"
      ],
      "metadata": {
        "id": "jBKJ0hMwrr8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xai_model = model"
      ],
      "metadata": {
        "id": "RNTwX_JPsbHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "background = x_trn[np.random.choice(x_trn.shape[0], 500, replace=False)]\n",
        "e = shap.DeepExplainer(xai_model, background)"
      ],
      "metadata": {
        "id": "SCV8CBp2rxKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_sel=x_tst[np.random.choice(x_trn.shape[0], 5, replace=False)]\n",
        "shap_values = e.shap_values(x_sel)\n",
        "shap.image_plot(shap_values, x_sel)"
      ],
      "metadata": {
        "id": "PWCAy-AdvXf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=np.argmax(model.predict(x_sel), axis=1)\n"
      ],
      "metadata": {
        "id": "ql2ArvCu0Rv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yyv6tLikhe_V"
      },
      "source": [
        "## Pretrained ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIj9dUYahe_c"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#img_size_target = 32;\n",
        "#img_input = tf.keras.layers.Input(shape=(img_size_target, img_size_target,1))\n",
        "#img_conc = tf.keras.layers.Concatenate()([img_input, img_input, img_input])\n",
        "\n",
        "from keras.applications.resnet import ResNet50\n",
        "\n",
        "## Loading VGG16 model\n",
        "pre_model = ResNet50(include_top=False, weights='imagenet', input_shape=(32,32,3))\n",
        "pre_model.trainable = True ## Not trainable weights\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "flatten_layer = layers.Flatten()\n",
        "dense_layer_1 = layers.Dense(128, activation='relu')\n",
        "dense_layer_2 = layers.Dense(32, activation='relu')\n",
        "prediction_layer = layers.Dense(2, activation='softmax')\n",
        "\n",
        "model = models.Sequential([\n",
        "    pre_model,\n",
        "    flatten_layer,\n",
        "    dense_layer_1,\n",
        "    dense_layer_2,\n",
        "    prediction_layer\n",
        "])\n",
        "\n",
        "pre_model.summary()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cT5IPKthe_d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuSyzT_Ehe_d"
      },
      "outputs": [],
      "source": [
        "one_hot_labels = keras.utils.np_utils.to_categorical(y_train, num_classes=2)\n",
        "hist_ResNet=model.fit(np.repeat(x_train.reshape((x_train.shape[0],32,32,1)), 3, axis=3), one_hot_labels, epochs=50, validation_split=0.2, batch_size=32, callbacks=[])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDVEEYmShe_d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Overall F1 score\n",
        "y_pred=np.argmax(model.predict(np.repeat(x_test.reshape((x_test.shape[0],32,32,1)), 3, axis=3)), axis=1)\n",
        "print(\"F1 Score:  \", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Precision: \", precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Recall:    \", recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Accuracy:    \", accuracy_score(y_test, y_pred))\n",
        "print(\"Accuracy:    \", np.mean(y_pred.reshape(1171,1)==y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeWw-rDFwi_Y"
      },
      "source": [
        "## Pretrained VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yygSBJOywi_f"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#img_size_target = 32;\n",
        "#img_input = tf.keras.layers.Input(shape=(img_size_target, img_size_target,1))\n",
        "#img_conc = tf.keras.layers.Concatenate()([img_input, img_input, img_input])\n",
        "\n",
        "from keras.applications.vgg19 import VGG19\n",
        "\n",
        "## Loading VGG16 model\n",
        "pre_model = VGG19(include_top=False, weights='imagenet', input_shape=(32,32,3))\n",
        "pre_model.trainable = False ## Not trainable weights\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "flatten_layer = layers.Flatten()\n",
        "dense_layer_1 = layers.Dense(128, activation='relu')\n",
        "dense_layer_2 = layers.Dense(32, activation='relu')\n",
        "prediction_layer = layers.Dense(2, activation='softmax')\n",
        "\n",
        "model = models.Sequential([\n",
        "    pre_model,\n",
        "    flatten_layer,\n",
        "    dense_layer_1,\n",
        "    dense_layer_2,\n",
        "    prediction_layer\n",
        "])\n",
        "\n",
        "pre_model.summary()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV9nWISEwi_f"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72JHap3_wi_f"
      },
      "outputs": [],
      "source": [
        "one_hot_labels = keras.utils.np_utils.to_categorical(y_train, num_classes=2)\n",
        "hist_v19=model.fit(np.repeat(x_train.reshape((x_train.shape[0],32,32,1)), 3, axis=3), one_hot_labels, epochs=50, validation_split=0.2, batch_size=32, callbacks=[])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq4n0IMUwi_g"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Overall F1 score\n",
        "y_pred=np.argmax(model.predict(np.repeat(x_test.reshape((x_test.shape[0],32,32,1)), 3, axis=3)), axis=1)\n",
        "print(\"F1 Score:  \", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Precision: \", precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Recall:    \", recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Accuracy:    \", accuracy_score(y_test, y_pred))\n",
        "print(\"Accuracy:    \", np.mean(y_pred.reshape(1171,1)==y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3gKp6fni9y2"
      },
      "source": [
        "## Pretrained Inception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9gcgxuVi7BX"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#img_size_target = 32;\n",
        "#img_input = tf.keras.layers.Input(shape=(img_size_target, img_size_target,1))\n",
        "#img_conc = tf.keras.layers.Concatenate()([img_input, img_input, img_input])\n",
        "\n",
        "from keras.applications import Xception\n",
        "\n",
        "## Loading Xception model\n",
        "pre_model = Xception(weights='imagenet',\n",
        "                              include_top=False,\n",
        "                              input_shape=(256, 256, 3))\n",
        "pre_model.trainable = False ## Not trainable weights\n",
        "\n",
        "from keras import layers, models\n",
        "\n",
        "flatten_layer = layers.Flatten()\n",
        "dense_layer_1 = layers.Dense(128, activation='relu')\n",
        "dense_layer_2 = layers.Dense(32, activation='relu')\n",
        "prediction_layer = layers.Dense(2, activation='softmax')\n",
        "\n",
        "model = models.Sequential([\n",
        "    pre_model,\n",
        "    flatten_layer,\n",
        "    dense_layer_1,\n",
        "    dense_layer_2,\n",
        "    prediction_layer\n",
        "])\n",
        "\n",
        "pre_model.summary()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdjUbbOUjjNN"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
        "one_hot_labels = keras.utils.np_utils.to_categorical(y_train, num_classes=2)\n",
        "\n",
        "hist_Inception=model.fit(np.repeat(x_train.reshape((x_train.shape[0],32,32,1)), 3, axis=3).resize(256,256), one_hot_labels, epochs=50, validation_split=0.2, batch_size=32, callbacks=[])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZLqNnTHj7Za"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Overall F1 score\n",
        "y_pred=np.argmax(model.predict(np.repeat(x_test.reshape((x_test.shape[0],32,32,1)), 3, axis=3)), axis=1)\n",
        "print(\"F1 Score:  \", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Precision: \", precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Recall:    \", recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Accuracy:    \", accuracy_score(y_test, y_pred))\n",
        "print(\"Accuracy:    \", np.mean(y_pred.reshape(1171,1)==y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvFxUWKME585"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZzwGPk1E8bG"
      },
      "outputs": [],
      "source": [
        "#plt.plot(hist1.history['loss']);\n",
        "plt.plot(hist_v16.history['loss']);\n",
        "plt.plot(hist_v19.history['loss']);\n",
        "plt.plot(hist_ResNet.history['loss']);\n",
        "plt.legend(['V16', 'V19', 'ResNet50'])\n",
        "\n",
        "#plt.plot(hist_ResNet.history['accuracy']);\n",
        "#plt.plot(hist_v19.history['val_loss']);\n",
        "#plt.plot(hist_v19.history['val_accuracy']);\n",
        "plt.xlabel('Epochs');\n",
        "plt.ylabel('Training Criteria');"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "U3gKp6fni9y2"
      ],
      "history_visible": true,
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}