{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Panperception/MML/blob/main/MML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTyO8Jc964st"
      },
      "source": [
        "## Load PD DBS Face Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOrA-Uq_tJqB"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp '/content/gdrive/My Drive/FacePD/PD_DBS_Data.mat' PD_DBS_Data.mat\n",
        "\n",
        "mat = scipy.io.loadmat('PD_DBS_Data.mat')\n",
        "x_train = mat['x_train']\n",
        "x_test = mat['x_test']\n",
        "y_train = mat['y_train']\n",
        "y_test = mat['y_test']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_trn = np.repeat(x_train.reshape((x_train.shape[0],32,32,1)), 3, axis=3)\n",
        "x_tst = np.repeat(x_test.reshape((x_test.shape[0],32,32,1)), 3, axis=3)"
      ],
      "metadata": {
        "id": "0MxApxnIJ7VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vqSCCUlH7YJ"
      },
      "outputs": [],
      "source": [
        "for k in range(10):\n",
        "  tmp=x_test[k*100,].reshape((32,32))\n",
        "  plt.subplot(1,10,k+1)\n",
        "  plt.imshow(np.tile(tmp,[3,1,1]).T)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MwfvxNcsvAP"
      },
      "source": [
        "## DNN Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fwl7sOGmsytb"
      },
      "outputs": [],
      "source": [
        "# !pip install np_utils\n",
        "# import np_utils\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "one_hot_labels =  keras.utils.to_categorical(y_train, num_classes=2)\n",
        "\n",
        "inputsize = 1024\n",
        "\n",
        "# define a 4 hidden layer DNN\n",
        "model_dmlp_adam = keras.Sequential()\n",
        "model_dmlp_adam.add(keras.layers.Input(shape=(inputsize,)))\n",
        "model_dmlp_adam.add(keras.layers.Dense(256, activation='sigmoid'))\n",
        "model_dmlp_adam.add(keras.layers.Dense(32, activation='relu'))\n",
        "model_dmlp_adam.add(keras.layers.Dense(2, activation='softmax'))\n",
        "model_dmlp_adam.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "hist1=model_dmlp_adam.fit(x_train, one_hot_labels, epochs=300, batch_size=32)\n",
        "\n",
        "plt.plot(hist1.history[\"loss\"]);\n",
        "plt.xlabel('Epochs');\n",
        "plt.ylabel('Training Error');\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91iBeVEJaT7W"
      },
      "source": [
        "## XAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n",
        "import shap"
      ],
      "metadata": {
        "id": "jP0BGs4BcRUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xai_model = model_dmlp_adam"
      ],
      "metadata": {
        "id": "zlKwZ8MBdTtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJvCToHZaT7W"
      },
      "outputs": [],
      "source": [
        "img_rows=32\n",
        "img_cols=32\n",
        "background = x_train[np.random.choice(x_train.shape[0], 500, replace=False)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-WgKEAmaT7W"
      },
      "outputs": [],
      "source": [
        "e = shap.DeepExplainer(xai_model, background)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVXFGLGmaT7W"
      },
      "outputs": [],
      "source": [
        "background = x_train[np.random.choice(x_train.shape[0], 500, replace=False)]\n",
        "e = shap.DeepExplainer(xai_model, background)\n",
        "shap_values = e.shap_values(x_test[1:5])\n",
        "shap.image_plot(shap_values, -x_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkYmfsk4aT7W"
      },
      "outputs": [],
      "source": [
        "s_values = [(np.reshape(x,(x.shape[0],img_rows,img_cols))) for x in shap_values]\n",
        "x_tst = np.reshape(x_test[1:5],(x_test[1:5].shape[0],img_rows,img_cols))\n",
        "shap.image_plot(s_values, -x_tst)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYmluWINaT7X"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.keras.losses import categorical_crossentropy\n",
        "from cxplain import MLPModelBuilder, ZeroMasking, CXPlain\n",
        "\n",
        "x_train, y_train, x_test = ....  # Your dataset\n",
        "explained_model = ...    # The model you wish to explain.\n",
        "\n",
        "# Define the model you want to use to explain your __explained_model__.\n",
        "# Here, we use a neural explanation model with a\n",
        "# multilayer perceptron (MLP) architecture.\n",
        "model_builder = MLPModelBuilder(num_layers=2, num_units=64, batch_size=256, learning_rate=0.001)\n",
        "\n",
        "# Define your masking operation - the method of simulating the\n",
        "# removal of input features used internally by CXPlain - ZeroMasking is typically a sensible default choice for tabular and image data.\n",
        "masking_operation = ZeroMasking()\n",
        "\n",
        "# Define the loss with which each input features' associated reduction in prediction error is calculated.\n",
        "loss = categorical_crossentropy\n",
        "\n",
        "# Build and fit a CXPlain instance.\n",
        "explainer = CXPlain(explained_model, model_builder, masking_operation, loss)\n",
        "explainer.fit(x_train, y_train)\n",
        "\n",
        "# Use the __explainer__ to obtain explanations for the predictions of your __explained_model__.\n",
        "attributions = explainer.explain(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZz2B8zYtJ9V"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Overall F1 score\n",
        "y_pred=np.argmax(model_dmlp_adam.predict(x_test), axis=1)\n",
        "print(\"F1 Score:  \", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Precision: \", precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Recall:    \", recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Accuracy:    \", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Overall F1 score\n",
        "\n",
        "#intermediate_layer_model = keras.Model(inputs=model_dmlp_SGD.input,\n",
        "#                                 outputs=model_dmlp_SGD.layers[0].output)\n",
        "#intermediate_output = intermediate_layer_model.predict(x_test)\n",
        "#ws=model_dmlp_SGD.layers[0].get_weights()\n",
        "#y00=np.matmul(x_test,ws[0])+np.tile(ws[1],[x_test.shape[0],1])\n",
        "\n",
        "\n",
        "y_pred=np.argmax(model_dmlp_SGD.predict(x_test), axis=1)\n",
        "print(\"F1 Score:  \", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Precision: \", precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Recall:    \", recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Accuracy:    \", accuracy_score(y_test, y_pred))\n",
        "#print(\"Accuracy:    \", np.mean(y_pred.reshape(1171,1)==y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BsMzxbcpyhR"
      },
      "source": [
        "## Pretrained VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqeXmqMRlkC2"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#img_size_target = 32;\n",
        "#img_input = tf.keras.layers.Input(shape=(img_size_target, img_size_target,1))\n",
        "#img_conc = tf.keras.layers.Concatenate()([img_input, img_input, img_input])\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "## Loading VGG16 model\n",
        "pre_model = VGG16(include_top=False, weights='imagenet', input_shape=(32,32,3))\n",
        "pre_model.trainable = False ## Not trainable weights\n",
        "\n",
        "from keras import layers, models\n",
        "\n",
        "flatten_layer = layers.Flatten()\n",
        "dense_layer_1 = layers.Dense(128, activation='relu')\n",
        "dense_layer_2 = layers.Dense(32, activation='relu')\n",
        "prediction_layer = layers.Dense(2, activation='softmax')\n",
        "\n",
        "model = models.Sequential([\n",
        "    pre_model,\n",
        "    flatten_layer,\n",
        "    dense_layer_1,\n",
        "    dense_layer_2,\n",
        "    prediction_layer\n",
        "])\n",
        "\n",
        "pre_model.summary()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dS_Mfwr-VGDv"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKrnIqxuXu0d"
      },
      "outputs": [],
      "source": [
        "one_hot_labels = keras.utils.np_utils.to_categorical(y_train, num_classes=2)\n",
        "hist_v16=model.fit(np.repeat(x_train.reshape((x_train.shape[0],32,32,1)), 3, axis=3), one_hot_labels, epochs=100, validation_split=0.2, batch_size=32, callbacks=[])\n",
        "\n",
        "plt.plot(hist_v16.history[\"loss\"]);\n",
        "plt.xlabel('Epochs');\n",
        "plt.ylabel('Training Error');\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVsHpjPNoMiA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Overall F1 score\n",
        "y_pred=np.argmax(model.predict(np.repeat(x_test.reshape((x_test.shape[0],32,32,1)), 3, axis=3)), axis=1)\n",
        "print(\"F1 Score:  \", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Precision: \", precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Recall:    \", recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Accuracy:    \", accuracy_score(y_test, y_pred))\n",
        "print(\"Accuracy:    \", np.mean(y_pred.reshape(1171,1)==y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###XAI Demo of VGG16 Model"
      ],
      "metadata": {
        "id": "jBKJ0hMwrr8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xai_model = model"
      ],
      "metadata": {
        "id": "RNTwX_JPsbHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "background = x_trn[np.random.choice(x_trn.shape[0], 500, replace=False)]\n",
        "e = shap.DeepExplainer(xai_model, background)"
      ],
      "metadata": {
        "id": "SCV8CBp2rxKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_sel=x_tst[np.random.choice(x_trn.shape[0], 5, replace=False)]\n",
        "shap_values = e.shap_values(x_sel)\n",
        "shap.image_plot(shap_values, x_sel)"
      ],
      "metadata": {
        "id": "PWCAy-AdvXf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=np.argmax(model.predict(x_sel), axis=1)\n"
      ],
      "metadata": {
        "id": "ql2ArvCu0Rv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yyv6tLikhe_V"
      },
      "source": [
        "## Pretrained ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIj9dUYahe_c"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#img_size_target = 32;\n",
        "#img_input = tf.keras.layers.Input(shape=(img_size_target, img_size_target,1))\n",
        "#img_conc = tf.keras.layers.Concatenate()([img_input, img_input, img_input])\n",
        "\n",
        "from keras.applications.resnet import ResNet50\n",
        "\n",
        "## Loading VGG16 model\n",
        "pre_model = ResNet50(include_top=False, weights='imagenet', input_shape=(32,32,3))\n",
        "pre_model.trainable = True ## Not trainable weights\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "flatten_layer = layers.Flatten()\n",
        "dense_layer_1 = layers.Dense(128, activation='relu')\n",
        "dense_layer_2 = layers.Dense(32, activation='relu')\n",
        "prediction_layer = layers.Dense(2, activation='softmax')\n",
        "\n",
        "model = models.Sequential([\n",
        "    pre_model,\n",
        "    flatten_layer,\n",
        "    dense_layer_1,\n",
        "    dense_layer_2,\n",
        "    prediction_layer\n",
        "])\n",
        "\n",
        "pre_model.summary()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cT5IPKthe_d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuSyzT_Ehe_d"
      },
      "outputs": [],
      "source": [
        "one_hot_labels = keras.utils.np_utils.to_categorical(y_train, num_classes=2)\n",
        "hist_ResNet=model.fit(np.repeat(x_train.reshape((x_train.shape[0],32,32,1)), 3, axis=3), one_hot_labels, epochs=50, validation_split=0.2, batch_size=32, callbacks=[])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDVEEYmShe_d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Overall F1 score\n",
        "y_pred=np.argmax(model.predict(np.repeat(x_test.reshape((x_test.shape[0],32,32,1)), 3, axis=3)), axis=1)\n",
        "print(\"F1 Score:  \", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Precision: \", precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Recall:    \", recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Accuracy:    \", accuracy_score(y_test, y_pred))\n",
        "print(\"Accuracy:    \", np.mean(y_pred.reshape(1171,1)==y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeWw-rDFwi_Y"
      },
      "source": [
        "## Pretrained VGG19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yygSBJOywi_f"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#img_size_target = 32;\n",
        "#img_input = tf.keras.layers.Input(shape=(img_size_target, img_size_target,1))\n",
        "#img_conc = tf.keras.layers.Concatenate()([img_input, img_input, img_input])\n",
        "\n",
        "from keras.applications.vgg19 import VGG19\n",
        "\n",
        "## Loading VGG16 model\n",
        "pre_model = VGG19(include_top=False, weights='imagenet', input_shape=(32,32,3))\n",
        "pre_model.trainable = False ## Not trainable weights\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "flatten_layer = layers.Flatten()\n",
        "dense_layer_1 = layers.Dense(128, activation='relu')\n",
        "dense_layer_2 = layers.Dense(32, activation='relu')\n",
        "prediction_layer = layers.Dense(2, activation='softmax')\n",
        "\n",
        "model = models.Sequential([\n",
        "    pre_model,\n",
        "    flatten_layer,\n",
        "    dense_layer_1,\n",
        "    dense_layer_2,\n",
        "    prediction_layer\n",
        "])\n",
        "\n",
        "pre_model.summary()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV9nWISEwi_f"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72JHap3_wi_f"
      },
      "outputs": [],
      "source": [
        "one_hot_labels = keras.utils.np_utils.to_categorical(y_train, num_classes=2)\n",
        "hist_v19=model.fit(np.repeat(x_train.reshape((x_train.shape[0],32,32,1)), 3, axis=3), one_hot_labels, epochs=50, validation_split=0.2, batch_size=32, callbacks=[])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq4n0IMUwi_g"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Overall F1 score\n",
        "y_pred=np.argmax(model.predict(np.repeat(x_test.reshape((x_test.shape[0],32,32,1)), 3, axis=3)), axis=1)\n",
        "print(\"F1 Score:  \", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Precision: \", precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Recall:    \", recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Accuracy:    \", accuracy_score(y_test, y_pred))\n",
        "print(\"Accuracy:    \", np.mean(y_pred.reshape(1171,1)==y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3gKp6fni9y2"
      },
      "source": [
        "## Pretrained Inception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9gcgxuVi7BX"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#img_size_target = 32;\n",
        "#img_input = tf.keras.layers.Input(shape=(img_size_target, img_size_target,1))\n",
        "#img_conc = tf.keras.layers.Concatenate()([img_input, img_input, img_input])\n",
        "\n",
        "from keras.applications import Xception\n",
        "\n",
        "## Loading Xception model\n",
        "pre_model = Xception(weights='imagenet',\n",
        "                              include_top=False,\n",
        "                              input_shape=(256, 256, 3))\n",
        "pre_model.trainable = False ## Not trainable weights\n",
        "\n",
        "from keras import layers, models\n",
        "\n",
        "flatten_layer = layers.Flatten()\n",
        "dense_layer_1 = layers.Dense(128, activation='relu')\n",
        "dense_layer_2 = layers.Dense(32, activation='relu')\n",
        "prediction_layer = layers.Dense(2, activation='softmax')\n",
        "\n",
        "model = models.Sequential([\n",
        "    pre_model,\n",
        "    flatten_layer,\n",
        "    dense_layer_1,\n",
        "    dense_layer_2,\n",
        "    prediction_layer\n",
        "])\n",
        "\n",
        "pre_model.summary()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdjUbbOUjjNN"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
        "one_hot_labels = keras.utils.np_utils.to_categorical(y_train, num_classes=2)\n",
        "\n",
        "hist_Inception=model.fit(np.repeat(x_train.reshape((x_train.shape[0],32,32,1)), 3, axis=3).resize(256,256), one_hot_labels, epochs=50, validation_split=0.2, batch_size=32, callbacks=[])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZLqNnTHj7Za"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Overall F1 score\n",
        "y_pred=np.argmax(model.predict(np.repeat(x_test.reshape((x_test.shape[0],32,32,1)), 3, axis=3)), axis=1)\n",
        "print(\"F1 Score:  \", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Precision: \", precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Recall:    \", recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Accuracy:    \", accuracy_score(y_test, y_pred))\n",
        "print(\"Accuracy:    \", np.mean(y_pred.reshape(1171,1)==y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvFxUWKME585"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZzwGPk1E8bG"
      },
      "outputs": [],
      "source": [
        "#plt.plot(hist1.history['loss']);\n",
        "plt.plot(hist_v16.history['loss']);\n",
        "plt.plot(hist_v19.history['loss']);\n",
        "plt.plot(hist_ResNet.history['loss']);\n",
        "plt.legend(['V16', 'V19', 'ResNet50'])\n",
        "\n",
        "#plt.plot(hist_ResNet.history['accuracy']);\n",
        "#plt.plot(hist_v19.history['val_loss']);\n",
        "#plt.plot(hist_v19.history['val_accuracy']);\n",
        "plt.xlabel('Epochs');\n",
        "plt.ylabel('Training Criteria');"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "U3gKp6fni9y2"
      ],
      "history_visible": true,
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}